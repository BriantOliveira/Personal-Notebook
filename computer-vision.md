**Edge Detection** - Identifying sharp changes in intensity in adjacent pixels.

**The canny edge detection technique**

The goal of edge detection is to identify the boundaries of objects within images.

In essence we'll be using a detection to try and find regions in an image where there is a sharp change in intensity a sharp change in color before diving into this.

It's important to recognize that an image can mirror it as a matrix an array of pixels a pixel contains

the light intensity at some location in the image.Each pixels intensity denoted by a numeric value that ranges from 0 to 255 and intensity value of zero

indicates no intensity.

```
[0 0 255 255]
[0 0 255 255]
[0 0 255 255]
[0 0 255 255]
```

If something is completely black Where s 255 represents maximum intensity something being completely. What's that being said gradient is that the change in brightness over a series of pixels. A strong gradient indicates a steep change whereas a small gradient represents a shallow change on the right hand side and you're looking at the gradient of the soccerball the outline of white pixels corresponds to the discontinuity in brightness at the points the strengthen gradient.

This helps us identify edges in our image since an edge is defined by the difference in intensity values in adjacent pixels.And wherever there is a sharp change in intensity a rapid change in brightness wherever there is a strong gradient there is a corresponding bright pixel in the gradient image by tracing out all of these pixels we obtain the edges.

We're going to use this intuition to detect the edges in our road image.This is a multi-step process.

**Step one** being to convert our image to grayscale. Why convert it to grayscale. Well as we discussed earlier images are made up of pixels. A three channel color image would have red green and blue channels each pixel a combination of three intensity values whereas a greyscale image only has one channel each pixel with only one intensity value ranging from 0 to 255.

The point being by using a grayscale image processing a single channel is faster than processing a three channel color image and less computational intensive. Let's start implementing this inside of them. We've already loaded and read our image into an array. Now what we'll do is import numb pie as the alias and P We're going to work with a copy of this array by setting a link image is equal to pie dog copy image.

Thus copying our array into a new variable it's imperative that you actually make a copy of the array instead of just setting lane image is equal to image. If we do this any changes we make to Lane image will also be reflected in the original viewable array.

Always ensure that you make a copy whenever working with a race instead of just setting them equal directly. So what we'll do now is we'll create a grayscale from the color image. We'll do that by setting a variable. Gray is equal to see to and from our open CV library will call the function CVT color which converts an image from one color space to another. We'll be converting lane image. And the second argument for an R G B to grayscale conversion. We can use the flag C-v to dot color underscore R G B to gray. Very intuitive.And now instead of showing the color image will show the gray image. If we go to our terminal Python Layne's that p y everything works out accordingly. This was step number one. Step number two of edge detection will be two.

**Gaussian Blur**

**Step two** is to now reduce noise and smooth in our image when detecting edges while it's important to accurately catch as many edges in the image as possible. We must filter out any image noise image noise can create false edges and ultimately affect edge detection. That's why it's imperative to filter it out and thus smoothen the image filtering out image noise and smoothing will be done with a Gaussian filter to understand the concept of a Gaussian filter. Recall that an image is stored as a collection of discrete pixels. Each of the pixels for a greyscale image is represented by a single number that describes the brightness of the pixel. For the sake of example how do we smooth in the following image.

_**The typical answer would be to modify the value of a pixel with the average value of the pixel intensities around it. Averaging out the pixels in the image to reduce noise will be done with the kernel. Essentially this kernel of normally distributed numbers is run across our entire image and sets each pixel about equal to the weighted average of its neighboring pixels thus smoothing our image**_. We're not going to go over kernel convolution and how it does it just know that when we write this line of code inside of our editor blur is equal to C-v to dog Gosden blur what we're doing is applying a gaussian blur on a greyscale image with a 5 by 5 kernel the size of the kernel is dependent on specific situations a 5 by 5 kernel is a good size for most cases.

But ultimately what that will do is returning a new image that we simply called blur. Applying the gaussian blur by involving our image with a kernel of Gaussian values reduces noise in our image back to our project set. Blur is equal to C-v to the gaussian blur. **We'll apply this blur in our gray scale image with our 5 by 5 kernel and we'll just leave the deviation is zero.**

The main thing you should take away from this is that we're using a gaussian blur to reduce noise in our greyscale scale image and now will simply show the blurred image. If we run this code Python Laine's dot p why there is our blurred greyscale image later on when we apply the Kenni method. It should be noted that this step was actually optional since the kidney function is going to internally apply a 5 by 5 Gaussian when we call it regardless. Now we know the theory with a 10 hour grayscale with smoothen data and reduced noise with a gaussian blur.

```
Strong Gradient        Small Gradient 
[0 0 255 255]            [0 0 20 20]
[0 0 255 255]            [0 0 20 20]
[0 0 255 255]            [0 0 20 20]
[0 0 255 255]            [0 0 20 20]
```

A small derivative is a small change in intensity whereas a big derivative is a big change by computing the derivative in all directions of the image. We're computing the gradients. Since recall the gradient is the change in brightness over a series of pixels. So when we call the kidney function it does all of that for us. It** computes the gradient in all directions of our blurred image CH and is then going to trace our strongest gradients as a series of white pixels**. **But notice these two arguments low threshold and high threshold. While this actually allows us to isolate the adjacent pixels that follow the strongest gradients if the gradient is larger than the upper threshold then it is accepted as an edge pixel.** If it is below the lower threshold it is rejected. If the gradient is between the thresholds then it will be accepted only if it is connected to a strong edge. The documentation itself recommends to use a ratio of 1 to 2 or 1 to 3 as such will use a low high threshold ratio of 1 to 3 50 to 150.

So far we've identified the edges in our image and isolated the region of interest. Now we'll make use of a technique that will detect straight lines in the image and thus identify the lane lines. This technique is known as hough transform will start by drawing a to d coordinates space of x and y and inside of it a straight line. We know that a straight line is represented by the equation Y is equal to x plus be nothing new so far. Just simple math our straight line has two parameters M and B. We're currently plotting it as a function of x and y but we can also represent this line in parametric space which we will call a space as B versus M. We now the y intercept of this line is 2. And the slope of the line is simply a rise over run. The change in y over the change in x which evaluates to three given the y intercept and slope this entire line can be plotted as a single point in Huff's space. Now imagine that instead of a line we had a single dot located at the coordinates 12 and 2. There are many possible lines that can pass through this dot each line with different values for M and B. You could have a line that crosses with M and be values of 2 and 8 3 and 6 4 and 4 5 and 2 6 and 0. So on and so forth. Notice that a single point in x and y space is represented by A-line and Huff's space. In other words by applauding the family of lines that goes through our point each line with its own distinct and B value pair. This produces an entire line of M in B value pairs enough space. What if we also had a point at in one. Once again there are many lines that can cross this point each line with different values for M and B. All of these different values for M and be represented by a line in parametric space. The point being whenever you see a series of points and we're told that these points are connected by some line. Ask yourself this question. What is that line. As previously mentioned there are many possible lines that can cross each point individually each line with different slope and wind or sub values. However there is one line that is consistent with both points. We can determine that by looking at the point of intersection enough space because that point of intersection represents the M and B values of a line consistent with crossing both of our points which in this case has slope and y intercept for Suppose there is one more point in our image space at the point sixteen and three. This point is also represented by A-line and parametric space.

Each point in that line the notes different values for it and B which once again correspond to different lines that can pass through this point but notice that there is another intersection at the same point which means that the line with the falling slope and y intercept four and four crosses all three of our dots. Why is this relevant. Well this idea of identifying possible lines from a series of points is how we're going to find lines in our gradient image. Recall that the gradient image is just a series of white points which represent edges in our image space. You and I can look at the very series of points in our image and automatically assume these points belong to a line. This series of points belongs to a line. So on and so forth. But what are the lines. What are their parameters. How do we identify them._** Well take these four points for example in our image space which correspond to the following Huff's space What we're going to do is first split our Huff's space into a grid. Each been inside of our grid corresponding to the slope and y intercept value of a candidate line.**_

For example what if I told you these points belong to a line. What is that line. Well I can see that there's points of intersection here. There are some here and some here as well. Well all of these points of intersection are inside of a single bin. For every point of intersection we're going to cast a vote inside of the bin that it belongs to the bin with the maximum number of votes that's going to be your line whatever and be value that this bin belongs to. That's the line that we're going to draw since it was voted as the line of best fit in describing our data. Now that we know the theory of how we're going to identify lines in our gradient image you would think to yourself are right enough talking time the code well not so fast. There's just one tiny problem. We still haven't taken into account vertical lines. Obviously if you try to compute the slope of a vertical line the change in x is zero. Which ultimately will always evaluate to a slope of infinity which is not something that we can represent and have space. Infinity is not really something we can work with anyway. We need a more robust representation of lines so that we don't encounter any numeric problems because clearly this form Y is equal to x plus be cannot represent vertical lines.

That being said instead of expressing our line with Cartesian coordinates system parameters M and B. Well instead express it in the polar coordinates system rho and theta such that our line equation can be read as RHO is equal to x Coast states plus y assigned data. If you're really interested in how this equation is derived feel free to ask me in the Q&A but the main idea is that this is still the equation of a line but in polar coordinates if I am to draw some line in Cartesian space the variable RHO is the perpendicular distance from the origin to that line. And data indicates the angle of inclination of the normal line from the X-axis which is measured in radians clockwise with respect to the positive x axis. Let's look at some examples. Suppose I had a point with exposition 5 and Y is equal to 2. And as you know this is a point and many lines can pass through this point including a vertical line.

_**We used to define lines passing through our points by their slope and y intercept and B but now they will be defined based on a row and data if we want to measure the perpendicular distance from the origin to the top of the line.**_ The angle of inclination of the normal line from the axis is simply 0 which works out to a distance of five. Another possible line that could pass through our point is a horizontal line the perpendicular distance from the origin to our line would correspond to an angle of 90 degrees which in radians is Pi over two.

Which ultimately works out to a distance of two. This line therefore is characterized by an angle theta of Pi over two and a distance a row of two just to strengthen our knowledge. Another possible line is the following whose perpendicular distance from origin to our line corresponds to an angle of 45 degrees from the positive axis that is Pi over 4 radians which works out to a distance a row of about 4.9 the point of all this being is that previously a point in image space represented a line in enough space. Whereas now with polar coordinates for a given point by plotting the family of lines that go through it each line or a distinct value for theta and row. We get a sinusoidal curve. This curve represents all of the different values for a row and data of lines that pass through our point.

This might look a bit intimidating but the concept is the exact same because imagine instead of one point we had 10 points which in turn results in 10 sinusoidal curse. As previously noted if the curves of different points intersect enough space and these points belong to the same line characterized by some row and data value. _**So this like before a line can be detected by finding the number of intersections between curves the more curves intersecting means that the line represented by that intersection crosses more points. In our case all ten of our curves intersect at a single point which means that there is a single line with some arrow and they value that crosses all ten of our dots. We can look at a more specific example with three dots in our Cartesian which represent the following sinusoidal curves.**_

All three lines intersect at the same points. Characterized by theta value of 0.9 to radians and perpendicular a distance of about nine point six secs. So that's the idea finding what slope best fits our data._** In our case it's the one with the following parameters.We can also apply the concept of voting that we discussed earlier such that our Huff's space is still in the form of a grid. And obviously this bin would have the maximum number of votes and just like before the bin and what the maximum number of votes that's going to be your line whatever theta in our valley that this bin belongs to.**_

That's the line that we draw. Since it was voted as the line of best fit in describing our data later on when we start implementing this we'll talk about the concept of thresholds. But for now that is all for transform. We're just trying to find the lines that best describe our points. And that's what we're going to use to find the lines that best find the etch points in our gradient.



